
<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Bogeng homepage</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic --> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GNJD50R0Z7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-GNJD50R0Z7');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Bogeng Song</h1>
        <p>NYU Master student <br>New York University</p>
        <p>Research Interest: <br>Computational neuroscience,Visual Perception, Attention, Computer Vision, Reinforcement learning, NeuroAI</a></p>
    <h3><a href="https://bogeng-song.github.io/">Home</a></h3>
        <h3><a href="https://bogeng-song.github.io/research.html">Research</a></h3>
    <h3><a href="https://bogeng-song.github.io/research/Bogeng_CV.pdf">CV</a></h3>  
        <h3><a href="https://bogeng-song.github.io/personal.html">Personal</a></h3>
    <b>Social</b><br>
        <div class="social-row">
          <a href="mailto:bs4283@nyu.edu" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a><br>
          <a href="https://github.com/bogeng-song"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <a href="https://github.com/bogengsong"><i class="fa fa-fw fa-github-square"></i> GitHub (less used)</a><br>
          <br>
        </div>
        <br>

   
    <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>

      </header>
      <section>

    <hr>

    <h2><a id="recent-papers-updated" class="anchor" href="#workingpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Working Papers</h2>
    <p style="margin:0"> <b>Implied gravity promotes coherent motion perception</b> <br> at <a href="https://scholar.google.co.uk/citations?user=ZNf4d7IAAAAJ&hl=en&oi=ao">Yi Jiang's Lab</a>, Institute of Psychology, Chinese Academy of Sciences. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>  The visual system can integrate local motion signals into a coherent global motion perception. How do the perceived gravitational forces influence the coherent perception? We designed a gravitational coherence threshold task to measure the visual discrimination of coherent global motion under different gravitational acceleration embedded in local motion signals. In three experiments, we found a consistent advantage when the acceleration of local motion conformed to natural gravity. These results could be obtained either in different experiment environments (real-world scenario in Experiment 1 and computer screen in Experiments 2 and 3) and visual angles (15°-by-15° in Experiments 1 and 2 and 8°-by-8° in Experiment 3). The results demonstrated that the human visual systems have an advantage in detecting the gravitational local motion signals and instantaneously integrating them into a coherent global motion.</p></div>
    <p style="margin:0"><button class="accordion">
      Project Description
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> In the current study, we designed a motion coherence threshold task to measure the visual discrimination of coherent motion stimuli that are accelerated or decelerated by natural gravity (1g) or reversed gravity (-1g). Using the QUEST threshold method, we measured the proportion of signal dots required for participants to discriminate the direction of upward or downward coherent motion, i.e., perceptual threshold, under different gravity conditions.<br>
      <img src="gravity_ex.jpg" height="250" width="250" alt="Tyler Ransom">  </p></div><br> 
 

    <p style="margin:0"> <b>Unethical amnesia brain: Memory and metacognitive distortion induced by dishonesty</b> <br> cooperate with <a href="https://andlab-um.com/">Haiyan Wu (AND)'s Lab</a> ,Centre for Cognitive and Brain Sciences (CCBS) at University of Macau (UM). <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>  Coming soon...</p></div>
    <p style="margin:0"><button class="accordion">
      Project Description and My Responsibilities
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> To test unethical amnesia behavior, we conducted two fMRI studies to identify how repeated dishonest responses over time distort memory accuracy and confidence. In this project, I mainly analyze behavioral data and try to model fMRI and mouse tracking data to predict the time-series subjects' memory accuracy change. Now, I'm basically done with the data analysis part, and I'm summarizing the results, doing paper review, and writing the paper.</p></div><br> 

    <p style="margin:0"> <b>Microsaccade rate and pupil size play a role in motion perception and index task difficulty</b> <br> at <a href="https://carrascolab.hosting.nyu.edu/">Carrasco Lab</a> ,NYU Department of Psychology. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p>  Coming soon...</p></div>
    <p style="margin:0"><button class="accordion">
      Project Description and My Responsibilities
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> In this project, I participated in the whole process except the data collection part.</p></div><br> 

    
    <hr>

    <h2><a id="published-papers-updated" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Published &amp; Forthcoming Papers</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.frontiersin.org/articles/10.3389/fnagi.2019.00152/full">Altered Static and Temporal Dynamic Amplitude of Low-Frequency Fluctuations in the Background Network During Working Memory States in Mild Cognitive Impairment</a><br> cooperate with <a href="https://www.researchgate.net/scientific-contributions/Pengyun-Wang-2105109369">Pengyun Wang Lab</a>, University of Chinese Academy of Sciences. <button class="accordion"> 
    Abstract
    </button>  
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Previous studies investigating working memory performance in patients with mild cognitive impairment (MCI) have mainly focused on the neural mechanisms of alterations in activation. To date, very few studies have investigated background network alterations in the working memory state. Therefore, the present study investigated the static and temporal dynamic changes in the background network in MCI patients during a working memory task. A hybrid delayed-match-to-sample task was used to examine working memory performance in MCI patients. Functional magnetic resonance imaging (fMRI) data were collected and the marker of amplitude of low-frequency fluctuations (ALFF) was used to investigate alterations in the background network. The present study demonstrated static and dynamic alterations of ALFF in MCI patients during working memory tasks, relative to the resting state. Traditional static analysis revealed that ALFF decreased in the right ventrolateral prefrontal cortex (VLPFC), right dorsolateral PFC (DLPFC), and left supplementary motor area for normal controls (NCs) in the working memory state. However, the same regions showed increased ALFF in MCI patients. Furthermore, relative to NCs, MCI patients demonstrated altered performance-related functional connectivity (FC) patterns, with the right VLPFC and right DLPFC as ROIs. In terms of temporal dynamic analysis, the present study found that in the working memory state dynamic ALFF of bilateral thalamus regions was increased in NCs but decreased in MCI patients. Additionally, MCI patients demonstrated altered performance-related coefficient of variation patterns; the regions in MCI patients were larger and more widely distributed in the parietal and temporal lobes, relative to NCs. This is the first study to examine static and temporal dynamic alterations of ALFF in the background network of MCI patients in working memory states. The results extend previous studies by providing a new perspective on the neural mechanisms of working memory deficits in MCI patients. </p></div>
    <p style="margin:0"><button class="accordion">
      My Responsibilities
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> In this project, I analyze fMRI data and write the paper results part.</p></div><br> 


    <hr>

    <h2><a id="conference" class="anchor" href="#conference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conference</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.visionsciences.org/presentation/?id=5177">Microsaccade rates reflect trial difficulty for perifoveal motion discrimination</a><br> VSS 2023, Author: Rania Ezzo, Bogeng Song, Bas Rokers, Marisa Carrasco. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Microsaccades, or small recurring eye movements, typically occur ~1-2 times per second. Although generally considered involuntary, the characteristics of these eye movements are task-dependent and affect performance. For example, microsaccades are flexibly allocated to precisely relocate gaze during high acuity tasks in the fovea and suppressed prior to the onset of a stimulus outside of the fovea during a motion discrimination task. Here we investigated whether and how microsaccade rates are adaptively modulated by trial difficulty when observers discriminate motion directions in the perifovea. METHODS. We used a 2AFC task to measure the discriminability of a Gabor drifting for 500ms in 1 of 8 reference directions (4 cardinal, 4 oblique) at 8 isoeccentric locations (7​​°). Observers reported a Gabor’s drift direction, which was slightly clockwise or counterclockwise with respect to a reference direction. The difficulty of each trial was varied in two ways: (a) cardinal vs. oblique directions; and (b) tilt offset between reference and Gabor direction. The tilt angles were randomized using a method of constant stimuli: the Gabor’s drift direction was offset from the reference direction by ± 0.5, 1, 2, 4 or 8°. RESULTS. First, we found that microsaccade rates were suppressed prior to stimulus onset. Second, microsaccade rates were modulated by trial difficulty in two ways: they decreased (1) as the angular offset between the target and standard decreased; and (2) when stimuli drifted in oblique rather than cardinal directions. CONCLUSION. Microsaccades were suppressed prior to stimulus presentation, and during the stimulus period for difficult discrimination tasks in the perifovea. This flexibility is consistent with the proposals that greater fixational stability can (1) mitigate potential blur during microsaccades, and (2) prolong the duration of evidence accumulation. As a result, microsaccades may serve as a marker of cognitive effort for visual tasks in the perifovea. </p></div><br>

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://bogeng-song.github.io/research/modvis.pdf">Automated delineation of visual area boundaries and eccentricities by a CNN using  functional, anatomical, and diffusion-weighted MRI data</a><br> MODVIS 2023, Author: Noah C. Benson, Bogeng Song, Toshikazu Miyata, Hiromasa Takemura, Jonathan Winawer. <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Delineating visual field maps and iso-eccentricities from fMRI data is an important  but  time-consuming  task  for  many  neuroimaging  studies  on  the  human  visual  cortex  because  the  traditional  methods  of  doing  so  using  retinotopic  mapping  experiments  require  substantial expertise  as  well  as  scanner,  computer,  and  human  time.  Automated  methods  based  on  gray matter  anatomy  or  a  combination  of  anatomy  and  functional  mapping  can  reduce  these  requirements  but  are  less  accurate  than  experts.  Convolutional  Neural  Networks  (CNNs)  are  powerful  tools  for  automated  medical  image  segmentation.  We  hypothesize  that  CNNs  can  define  visual  area  boundaries  with  high  accuracy.  We  trained  U-Net  CNNs  with  ResNet18  backbones  to  predict  either  V1,  V2,  and  V3  boundaries  or  5  regions  of  iso-eccentricity  using  human-labeled  maps.  Separate  CNNs  were  trained  to  predict  these  regions  using  different  combinations  of  the  following  input  data:  (1)  anatomical  data  from  a  T1-weighted  image  only,  (2)  anatomical  data  from  T1-weighted  and  T2*-weighted  images,  (3)  white-matter  tract  endpoints  from  diffusion-weighted  imaging,  (4)  functional  data  from  retinotopic  mapping.  All  CNNs  using  functional  data  had  cross-validated  accuracy  that  was  statistically  indistinguishable  from  the  inter-rater  reliability  of  the  training  dataset  (dice  coefficient  of  92%)  while  the  CNNs  lacking  functional  data  had  lower  but  similar  accuracies  (~75%).  Existing  models  that  do  not  use  CNNs  had  accuracies  lower  than  any  of  the  CNNs.  These  results  demonstrate  that  with  current  methods  and  data  quality,  CNNs  can  replace  the  time  and  effort  of  human  experts  in  manually defining early retinotopic maps, but cannot yet replace the acquisition of functional data. </p></div><br>

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://bogeng-song.github.io/research/MEM_conference.pdf">How bio-inspired attention affects task performance in visual and auditory models </a><br> NYU Minds, Brains, and Machine Summer Poster Conference, Author: Bogeng Song, Grace Lindsay. <br>

    <hr>

    <h2><a id="work-experience" class="anchor" href="#workexperience" aria-hidden="true"><span class="octicon octicon-link"></span></a>Work Experience</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://icahn.mssm.edu/research/depression-anxiety-center">The Depression and Anxiety Center at Mount Sinai</a><br> Summer internship student (2022). <br><button class="accordion">
      My Responsibilities
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Use afni and SPM to analyze fMRI data, use psychopy to write experimental programs, basic data analysis and organization. </p></div><br>
 
    <hr>

    <h2><a id="project" class="anchor" href="#otherproject" aria-hidden="true"><span class="octicon octicon-link"></span></a>Other project</h2>

    <p style="margin:0"> <b>Motion discrimination around the visual field</b> <br> at <a href="https://carrascolab.hosting.nyu.edu/">Carrasco Lab </a> New York University <br><button class="accordion">
      Project Description
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> We used psychophysical and eye-tracking methods to measure behavioral differences for different motion directions (e.g., radial versus tangential). To model the behavioral data, we fit psychophysical curves, and compare performance for different motion directions. </p></div><br>
 

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://bogeng-song.github.io/research/Didwania-Saxena-Song-ccm-final.pdf"> Differential contributions of episodic and semantic memory to story-telling </a> <br> Computational cognitive modeling final project <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Our memory is an integral centrepiece in the process of storytelling however, our intuition leads us to believe that we use different types of memory and memory retrieval for different types of stories. To further examine the relationships, we built a framework of different computational models to better understand the cognitive processes that people use while constructing a type of story. Our primary dataset, hippoCorpusV2, contains 6,854 diary-like short stories individually labeled into three categories: recall, imagine and retold. We used relevantMachine Learning models and techniques to classify these three types of stories, and extract the corresponding features to compare with our conclusions from human behavior experiments to better understand people's cognitive processes. We found that our model results and behavioral results are similar, and there are three main characteristics that help us distinguish the three types of stories: the time it takes to build the story, the amount of concrete, specific events mentioned in a story, and detailed, sensory information providing background color to the story. From these results, we can infer that recall stories are based on the direct retrieval of episodic memory, while imagined stories are mainly generated based on general knowledge of semantic memory. While retold stories do retain some details in episodic memory, they also require general knowledge due to the inherent human tendency to forget trivial details. </p></div><br>
 
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://bogeng-song.github.io/research/Final_Report_bml.pdf"> Bayesian Semi Supervised Learning with Function-Space Variational Inference </a><br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Existing work on Semi-Supervised Learning with Variational Bayesian Inference and Maximum Uncertainty Regularization has shown clear improvements in classification errors of various Consistency Regularization based methods. Functional Space Variational Inference is an improvement to Variational Inference. We propose a method combining Functional Space Variational Inference and Consistency Regularization by minimizing the KL divergence of distributions over functions. We apply our method to the partially labeled datasets and compare the three ways to realize our method. </p></div><br>

    <p style="margin:0"> <b>Reward motivation affects the cognitive mechanism of attention selection and attention inhibition</b> <br> Undergraduate Thesis <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Increasing research has shown that objects associated with rewards can effectively capture attention. Perceptual load theory believes that under low load conditions, the current task just uses only a proportion of attention resource, the spared resource will automatically spread to distractor ; but under high perceptual load conditions, all attention resources are  consumed, and no extra attention resources are available to process interference stimuli. However, it is not known that after the interference stimulus and the reward are established, the interference stimulus associated with the reward can effectively capture the attention resource under high and low load conditions. This study aims to explore this issue in conjunction with the learning-test paradigm and ERP techniques. During the experiment, the subjects were asked to link the colors (red, green) to the high and low rewards during the learning task. In the test task, the handy experimental paradigm was used to explore the centrality by setting the interference stimuli and perceived load levels of different colors. The amplitude of the P1 band around the concave changes. We assume that regardless of the level of load, the interfering stimulus associated with the high reward will always produce a corrected P1 amplitude. Behavioral results show significant differences in the correct rates for high load and low load conditions. The results of EEG showed that in the occipital cortex, the reward was significant. Compared with the low reward condition, the P1 amplitude was higher under the high reward condition; and the interaction between the reward and the perceptual load was significant, and the simple effect test showed that it was high or low. Under the perceptual load condition, there is a significant difference in the P1 amplitude caused by the stimulation of the high and low rewards, and in the case of low perceptual load, the difference between the high and low rewards is significantly greater than the difference between the high and low rewards under the high perceptual load. According to the results, even under high-perceptual load conditions, the interfering stimulus associated with the high reward still captures attention. Attention to irrelevant stimuli captures a common adjustment of the value-driven attentional effect and the perceived load level of the current task. </p></div><br>

    <p style="margin:0"> <b> Predicting fMRI Response of Human Visual System with Pre-trained Visual-Textual Neural Networks (The Algonauts Project 2023)</b> <br> Team member <br><button class="accordion">
      My Responsibilities
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Try Masked AutoEncoder (MAE) as a pre-training method, providing some neuroscience knowledge to help improve prediction scores. </p></div><br>


  </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script> 
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
